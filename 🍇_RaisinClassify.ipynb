{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "# a) Read the uploaded dataset\n",
        "file_path = '/content/Raisin_Dataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# b) Display the first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# c) Check for null values\n",
        "print(df.isnull().sum())  # Check for missing values\n",
        "\n",
        "# d) Convert the 'Class' column into binary (Kecimen as 0 and Besni as 1)\n",
        "df['Class'] = df['Class'].map({'Kecimen': 0, 'Besni': 1})\n",
        "\n",
        "# e) Feature importance using Chi-Square\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Normalize feature values for chi2 test\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Compute Chi-Square scores\n",
        "chi_scores, p_values = chi2(X_scaled, y)\n",
        "feature_importance = pd.DataFrame({'Feature': X.columns, 'Chi2 Score': chi_scores, 'p-value': p_values})\n",
        "print(feature_importance)\n",
        "\n",
        "# Discard least important feature based on chi-square value\n",
        "X = df.drop(columns=['MinorAxisLength'])  # Example, discard based on results\n",
        "\n",
        "# Step 2: Split the dataset (80% for training, 20% for testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train a Decision Tree Classifier with default parameters\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the model on test data\n",
        "y_pred = clf.predict(X_test)\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "\n",
        "# Step 5: Train with different criteria (entropy and log_loss) and evaluate\n",
        "# Using entropy\n",
        "clf_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "clf_entropy.fit(X_train, y_train)\n",
        "y_pred_entropy = clf_entropy.predict(X_test)\n",
        "print('Entropy - Accuracy:', accuracy_score(y_test, y_pred_entropy))\n",
        "\n",
        "# Using log_loss\n",
        "clf_log_loss = DecisionTreeClassifier(criterion='log_loss', random_state=42)\n",
        "clf_log_loss.fit(X_train, y_train)\n",
        "y_pred_log_loss = clf_log_loss.predict(X_test)\n",
        "print('Log Loss - Accuracy:', accuracy_score(y_test, y_pred_log_loss))\n",
        "\n",
        "# Step 6: Parameter tuning using GridSearchCV (corrected max_features values)\n",
        "param_grid = {\n",
        "    'max_depth': [10, 100],\n",
        "    'min_samples_split': [4, 6, 8],\n",
        "    'max_features': ['sqrt', 'log2', None]  # Removed 'auto'\n",
        "}\n",
        "\n",
        "# Grid Search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model performance\n",
        "print('Best Parameters:', grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Step 7: Evaluate the best model\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print('Best Model - Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_best))\n",
        "print('Best Model - Accuracy:', accuracy_score(y_test, y_pred_best))\n",
        "print('Best Model - Precision:', precision_score(y_test, y_pred_best))\n",
        "print('Best Model - Recall:', recall_score(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Md6T2vM0vq9",
        "outputId": "0ebb2f58-d84f-4734-acb0-ff4caeadd3bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
            "0  87524       442.246011       253.291155      0.819738       90546   \n",
            "1  75166       406.690687       243.032436      0.801805       78789   \n",
            "2  90856       442.267048       266.328318      0.798354       93717   \n",
            "3  45928       286.540559       208.760042      0.684989       47336   \n",
            "4  79408       352.190770       290.827533      0.564011       81463   \n",
            "\n",
            "     Extent  Perimeter    Class  \n",
            "0  0.758651   1184.040  Kecimen  \n",
            "1  0.684130   1121.786  Kecimen  \n",
            "2  0.637613   1208.575  Kecimen  \n",
            "3  0.699599    844.162  Kecimen  \n",
            "4  0.792772   1073.251  Kecimen  \n",
            "Area               0\n",
            "MajorAxisLength    0\n",
            "MinorAxisLength    0\n",
            "Eccentricity       0\n",
            "ConvexArea         0\n",
            "Extent             0\n",
            "Perimeter          0\n",
            "Class              0\n",
            "dtype: int64\n",
            "           Feature  Chi2 Score       p-value\n",
            "0             Area   40.913845  1.590901e-10\n",
            "1  MajorAxisLength   34.625936  3.995473e-09\n",
            "2  MinorAxisLength   14.726018  1.243189e-04\n",
            "3     Eccentricity    5.311431  2.118595e-02\n",
            "4       ConvexArea   35.662379  2.346520e-09\n",
            "5           Extent    0.422287  5.157982e-01\n",
            "6        Perimeter   26.290246  2.937686e-07\n",
            "Confusion Matrix:\n",
            " [[94  0]\n",
            " [ 0 86]]\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "Entropy - Accuracy: 1.0\n",
            "Log Loss - Accuracy: 1.0\n",
            "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 4}\n",
            "Best Model - Confusion Matrix:\n",
            " [[94  0]\n",
            " [ 0 86]]\n",
            "Best Model - Accuracy: 1.0\n",
            "Best Model - Precision: 1.0\n",
            "Best Model - Recall: 1.0\n"
          ]
        }
      ]
    }
  ]
}